#!/usr/bin/env python3
"""
BTC/USDT Historical Data Importer from Binance API
Imports 1-minute candlestick data starting from Binance launch (August 2017)
Only imports new data that doesn't exist in the database.

Features:
- üìä Progress tracking with percentage completion  
- üîÑ Batch processing for efficiency
- üõ°Ô∏è Error recovery - can restart where it left off
- ‚è∞ Rate limiting to respect Binance API limits
- üö´ Duplicate prevention
- üìà Real-time statistics and ETA
"""

import pymssql
import requests
import time
from datetime import datetime, timezone, timedelta
from typing import List, Tuple, Optional
import sys

class BTCDataImporter:
    def __init__(self):
        self.binance_api_url = "https://api.binance.com/api/v3/klines"
        self.symbol = "BTCUSDT"
        self.interval = "1m"
        self.limit = 1000  # Max records per API call
        
        # Binance BTC/USDT trading started August 17, 2017
        self.start_timestamp = int(datetime(2017, 8, 17, tzinfo=timezone.utc).timestamp() * 1000)
        
    def get_database_connection(self):
        """Get database connection"""
        return pymssql.connect(
            server='localhost',
            port=1433,
            user='sa',
            password='MyPassword123#',
            database='MyFirstDatabase'
        )
    
    def get_latest_timestamp(self) -> Optional[int]:
        """Get the latest OpenTime timestamp from database for BTC 1m data"""
        conn = self.get_database_connection()
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                SELECT MAX(OpenTime) 
                FROM MarketData 
                WHERE Symbol = %s AND TimeFrame = %s
            """, ('BTC', '1m'))
            
            result = cursor.fetchone()
            latest_time = result[0] if result[0] else None
            
            if latest_time:
                # Convert to timestamp (milliseconds) and add 1 minute to avoid duplicates
                timestamp = int(latest_time.timestamp() * 1000) + 60000
                print(f"üìÖ Latest data in DB: {latest_time}")
                return timestamp
            else:
                print("üìÖ No existing data found, starting from Binance launch (Aug 17, 2017)")
                return self.start_timestamp
                
        except Exception as e:
            print(f"‚ùå Error checking latest timestamp: {e}")
            return self.start_timestamp
        finally:
            cursor.close()
            conn.close()
    
    def fetch_klines(self, start_time: int, end_time: Optional[int] = None) -> List:
        """Fetch kline data from Binance API"""
        params = {
            'symbol': self.symbol,
            'interval': self.interval,
            'startTime': start_time,
            'limit': self.limit
        }
        
        if end_time:
            params['endTime'] = end_time
        
        try:
            response = requests.get(self.binance_api_url, params=params)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            print(f"‚ùå API Error: {e}")
            return []
    
    def convert_kline_to_db_format(self, kline: List) -> Tuple:
        """Convert Binance kline format to database format"""
        # Binance kline format: [open_time, open, high, low, close, volume, close_time, ...]
        open_time = datetime.fromtimestamp(kline[0] / 1000, tz=timezone.utc)
        close_time = datetime.fromtimestamp(kline[6] / 1000, tz=timezone.utc)
        
        return (
            'BTC',                    # Symbol
            '1m',                     # TimeFrame
            open_time,                # OpenTime
            float(kline[1]),          # OpenPrice
            float(kline[2]),          # HighPrice
            float(kline[3]),          # LowPrice
            float(kline[4]),          # ClosePrice
            float(kline[5]),          # Volume
            close_time                # CloseTime
        )
    
    def bulk_insert_data(self, data_batch: List[Tuple]) -> int:
        """Insert batch of data into database"""
        if not data_batch:
            return 0
        
        conn = self.get_database_connection()
        cursor = conn.cursor()
        
        try:
            # Use executemany for efficient bulk insert
            cursor.executemany("""
                INSERT INTO MarketData 
                (Symbol, TimeFrame, OpenTime, OpenPrice, HighPrice, LowPrice, ClosePrice, Volume, CloseTime)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
            """, data_batch)
            
            conn.commit()
            return len(data_batch)
            
        except Exception as e:
            print(f"‚ùå Database insert error: {e}")
            conn.rollback()
            return 0
        finally:
            cursor.close()
            conn.close()
    
    def calculate_progress_stats(self, current_timestamp: int, start_timestamp: int, end_timestamp: int, 
                               batch_count: int, total_records: int, start_import_time: datetime):
        """Calculate and display detailed progress statistics with examples"""
        
        # PROGRESS BER√ÑKNING F√ñRKLARING:
        # ==============================
        # Progress baseras p√• tidsintervall, inte antal batches, f√∂r mer exakt uppskattning
        
        # 1. Ber√§kna totalt tidsintervall som ska t√§ckas
        total_time_span = end_timestamp - start_timestamp  # i millisekunder
        
        # 2. Ber√§kna hur mycket som redan √§r klart  
        completed_time_span = current_timestamp - start_timestamp  # i millisekunder
        
        # 3. Ber√§kna progress i procent
        # Exempel: Om vi ska h√§mta 2017-08-17 till 2025-10-15
        # - total_time_span = hela perioden (8 √•r i ms)
        # - completed_time_span = fr√•n start till nuvarande batch (t.ex. 2019-03-01)
        # - progress = (2 √•r / 8 √•r) √ó 100 = 25%
        progress_percent = (completed_time_span / total_time_span * 100) if total_time_span > 0 else 100
        
        # ETA BER√ÑKNING F√ñRKLARING:
        # =========================
        # Anv√§nder faktisk tid vs progress f√∂r att uppskatta slutf√∂rt tid
        
        elapsed_time = datetime.now() - start_import_time
        elapsed_seconds = elapsed_time.total_seconds()
        
        if progress_percent > 0:
            # Exempel p√• ETA-ber√§kning:
            # - Vi har jobbat i 120 sekunder och kommit 25% av v√§gen
            # - Uppskattad total tid: 120 √∑ 0.25 = 480 sekunder
            # - Kvarvarande tid: 480 - 120 = 360 sekunder (6 minuter)
            estimated_total_seconds = elapsed_seconds / (progress_percent / 100)
            remaining_seconds = estimated_total_seconds - elapsed_seconds
            eta = datetime.now() + timedelta(seconds=remaining_seconds)
        else:
            eta = None
        
        # Current date being processed
        current_date = datetime.fromtimestamp(current_timestamp/1000, tz=timezone.utc)
        
        # Display progress bar
        bar_length = 30
        filled_length = int(bar_length * progress_percent / 100)
        bar = '‚ñà' * filled_length + '‚ñë' * (bar_length - filled_length)
        
        print(f"\nüìä PROGRESS RAPPORT")
        print(f"‚îú‚îÄ Progress: [{bar}] {progress_percent:.1f}%")
        print(f"‚îú‚îÄ Current Date: {current_date.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"‚îú‚îÄ Batches: {batch_count}")
        print(f"‚îú‚îÄ Records: {total_records:,}")
        print(f"‚îú‚îÄ Elapsed: {str(elapsed_time).split('.')[0]}")
        if eta:
            print(f"‚îî‚îÄ ETA: {eta.strftime('%H:%M:%S')} ({remaining_seconds/60:.0f} min kvar)")
        else:
            print(f"‚îî‚îÄ ETA: Ber√§knar...")

    def import_historical_data(self):
        """Main function to import all historical data with enhanced progress tracking"""
        print("üöÄ BTC/USDT HISTORICAL DATA IMPORTER")
        print("=" * 60)
        
        # Get starting point
        start_time = self.get_latest_timestamp()
        current_time = int(datetime.now(timezone.utc).timestamp() * 1000)
        
        if start_time >= current_time:
            print("‚úÖ Databasen √§r redan uppdaterad!")
            return
        
        # Calculate scope and batch requirements
        start_date = datetime.fromtimestamp(start_time/1000, tz=timezone.utc)
        end_date = datetime.fromtimestamp(current_time/1000, tz=timezone.utc)
        
        # BATCH-BER√ÑKNING F√ñRKLARING:
        # ============================
        # 1. Ber√§kna totalt antal minuter mellan start och slut
        total_minutes = int((end_date - start_date).total_seconds() / 60)
        
        # 2. Ber√§kna antal API-calls som beh√∂vs
        # Binance API: Max 1000 records per call (self.limit = 1000)
        # 
        # Exempel: Om vi beh√∂ver 2500 minuters data:
        # - 2500 datapunkter (1 per minut)
        # - 2500 √∑ 1000 = 2.5 ‚Üí avrunda upp√•t = 3 batches
        # - Batch 1: 1000 records (minut 0-999)
        # - Batch 2: 1000 records (minut 1000-1999) 
        # - Batch 3: 500 records (minut 2000-2499)
        #
        # Formeln: (total_records + batch_size - 1) // batch_size
        # Detta √§r "ceiling division" - avrundar alltid upp√•t
        estimated_batches = (total_minutes + self.limit - 1) // self.limit
        
        # EXEMPEL P√Ö BER√ÑKNING:
        # =====================
        # Scenario 1: 1 √•r historisk data
        # - 1 √•r = 365 dagar √ó 24 timmar √ó 60 minuter = 525,600 minuter
        # - 525,600 √∑ 1000 = 525.6 ‚Üí 526 batches
        # - Tid: 526 √ó 0.1 sekund = 52.6 sekunder (med rate limiting)
        #
        # Scenario 2: Fr√•n Binance start (Aug 2017) till idag (~8 √•r)
        # - 8 √•r ‚âà 4,200,000 minuter
        # - 4,200,000 √∑ 1000 = 4,200 batches
        # - Tid: 4,200 √ó 0.1 sekund = 420 sekunder = 7 minuter
        
        print(f"üìÖ Period: {start_date.strftime('%Y-%m-%d %H:%M')} ‚Üí {end_date.strftime('%Y-%m-%d %H:%M')}")
        print(f"üìä Uppskattade datapunkter: {total_minutes:,}")
        print(f"üìä Uppskattade batches: {estimated_batches:,}")
        print(f"‚è∞ Uppskattad tid: {estimated_batches * 0.1 / 60:.0f}-{estimated_batches * 0.5 / 60:.0f} minuter")
        print(f"ÔøΩ Lagrar i: MarketData (Symbol='BTC', TimeFrame='1m')")
        print("=" * 60)
        
        # Import tracking
        total_records = 0
        batch_count = 0
        start_import_time = datetime.now()
        original_start_time = start_time
        
        try:
            while start_time < current_time:
                batch_count += 1
                
                # Fetch data from Binance
                klines = self.fetch_klines(start_time)
                
                if not klines:
                    print("‚ö†Ô∏è Ingen mer data tillg√§nglig fr√•n Binance API")
                    break
                
                # Convert to database format
                db_data = []
                for kline in klines:
                    db_record = self.convert_kline_to_db_format(kline)
                    db_data.append(db_record)
                
                # Insert into database
                inserted = self.bulk_insert_data(db_data)
                total_records += inserted
                
                # Update start_time for next batch
                if klines:
                    start_time = klines[-1][0] + 1
                
                # Show progress every 20 batches or if it's the first few
                if batch_count <= 5 or batch_count % 20 == 0:
                    self.calculate_progress_stats(
                        start_time, original_start_time, current_time,
                        batch_count, total_records, start_import_time
                    )
                elif batch_count % 5 == 0:
                    # Quick update every 5 batches
                    progress = ((start_time - original_start_time) / (current_time - original_start_time) * 100)
                    current_date = datetime.fromtimestamp(start_time/1000, tz=timezone.utc)
                    print(f"üìà {progress:.1f}% - Batch {batch_count} - {current_date.strftime('%Y-%m-%d %H:%M')} - {total_records:,} records")
                
                # Rate limiting - respekterar Binance limits
                time.sleep(0.1)
                
                # Error recovery checkpoint every 100 batches
                if batch_count % 100 == 0:
                    checkpoint_date = datetime.fromtimestamp(start_time/1000, tz=timezone.utc)
                    print(f"ÔøΩ Checkpoint: {checkpoint_date.strftime('%Y-%m-%d %H:%M')} - {total_records:,} records saved")
        
        except KeyboardInterrupt:
            print(f"\n‚ö†Ô∏è Import avbruten av anv√§ndare vid batch {batch_count}")
            print(f"üíæ {total_records:,} records har sparats i databasen")
            checkpoint_date = datetime.fromtimestamp(start_time/1000, tz=timezone.utc)
            print(f"üîÑ N√§sta start: {checkpoint_date.strftime('%Y-%m-%d %H:%M')}")
            return
        
        except Exception as e:
            print(f"\n‚ùå Fel under import: {e}")
            print(f"ÔøΩ {total_records:,} records har sparats innan felet")
            return
        
        # Final statistics
        elapsed_time = datetime.now() - start_import_time
        print("\n" + "=" * 60)
        print("üéâ IMPORT SLUTF√ñRD!")
        print(f"üìä Totalt antal records: {total_records:,}")
        print(f"üìä Antal batches: {batch_count}")
        print(f"‚è∞ Total tid: {str(elapsed_time).split('.')[0]}")
        print(f"‚ö° Hastighet: {total_records/elapsed_time.total_seconds():.0f} records/sekund")
        print(f"üìÖ Data t√§cker nu: {datetime.fromtimestamp(original_start_time/1000, tz=timezone.utc).strftime('%Y-%m-%d')} ‚Üí {datetime.now().strftime('%Y-%m-%d')}")
        print("=" * 60)

def main():
    """Main execution function"""
    importer = BTCDataImporter()
    
    try:
        importer.import_historical_data()
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Import interrupted by user")
    except Exception as e:
        print(f"‚ùå Unexpected error: {e}")

if __name__ == "__main__":
    main()